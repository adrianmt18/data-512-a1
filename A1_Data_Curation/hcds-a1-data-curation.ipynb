{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook processes wikipedia page view data from January 2008 through August 2019.\n",
    "\n",
    "Data was gathered from the <a href=\"https://wikimedia.org/api/rest_v1/\">Wikimedia REST API</a>,\n",
    "Wikimedia Foundation, 2018. CC-BY-SA 3.0\n",
    "\n",
    "Through the two APIs provided by Wikimedia (<a href=\"https://wikimedia.org/api/rest_v1/#!/Legacy_data/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end\">one for legacy data</a>, <a href=\"https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end\">one for the updated data definitions</a>), five calls are made to retrieve the relevant data. The responses are stored in respective json files, each named in the following format:\n",
    "\n",
    "apiname_accesstype_firstmonth-lastmonth.json\n",
    "* api values: pagecounts, pageviews\n",
    "* page count accesstype values: desktop-site, mobile-site\n",
    "* page view accesstype values: desktop, mobile-app, mobile-web\n",
    "\n",
    "Next, each json file will be pulled into a Pandas dataframe. From there, they will be merged into a single dataframe by matching timestamps and stored in a csv file, which will be used for analysis. The records are aggregated by month and year.\n",
    "For this step, it should be noted that although the new pageview definitions discern between mobile app page views and mobile browser page views, they are summed into a single value representing all mobile traffic for the purposes of this analysis. Entries with 0 page views/counts indicate no data being available for that month under that access method.\n",
    "\n",
    "In the final plot, all the page view counts are scaled down by factor of 1,000,000. Also, after the page view definitions changed in May 2015, through July 2016, both APIs were in effect. Consequently, there is some overlap in data. This is indicated in the plot by a shift from dotted lines to solid lines, solid lines representing the new definitions. The new definitions differentiated user views from crawler views. The solid lines in the plot reflect the crawler view counts being ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from numpy import NaN\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "import json\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(endpoint,parameters):\n",
    "    call = requests.get(endpoint.format(**parameters), headers=headers)\n",
    "    response = call.json()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Generate and dump pagecounts json file\n",
    "# see: https://wikimedia.org/api/rest_v1/#!/Legacy_data/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end\n",
    "def dump_pagecounts(start='2008010100', end='2016080100'):\n",
    "    api = 'pagecounts'\n",
    "    # Available values for 'access-site' parameter\n",
    "    list_access_site = list(('desktop-site','mobile-site'))\n",
    "    end_point = 'https://wikimedia.org/api/rest_v1/metrics/legacy/pagecounts/aggregate/{project}/{access-site}/{granularity}/{start}/{end}'\n",
    "    \n",
    "    for ac_site in list_access_site:\n",
    "        params = {\"project\" : \"en.wikipedia.org\",\n",
    "                      \"access-site\" : ac_site,\n",
    "                      \"granularity\" : \"monthly\",\n",
    "                      \"start\" : start,\n",
    "                    # for end, use 1st day of month following final month of data\n",
    "                      \"end\" : end\n",
    "                 }\n",
    "        \n",
    "        f_name = api + \"-\" + ac_site + \"-\" + start[0:-4] + \"-\" + end[0:-4] + \".json\"\n",
    "        json.dump(api_call(end_point, params), open(f_name,\"w\"))\n",
    "        \n",
    "    return\n",
    "\n",
    "# Generate and dump pageviews json file\n",
    "# see: https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end\n",
    "def dump_pageviews(start='2015070100', end='2019090100'):\n",
    "    api = 'pageviews'\n",
    "    # Available values for 'access' parameter\n",
    "    list_access = list(('desktop','mobile-app','mobile-web'))\n",
    "    end_point = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/{project}/{access}/{agent}/{granularity}/{start}/{end}'\n",
    "    \n",
    "    for acs in list_access:\n",
    "        params = {\"project\" : \"en.wikipedia.org\",\n",
    "                      \"access\" : acs,\n",
    "                      \"agent\" : \"user\",\n",
    "                      \"granularity\" : \"monthly\",\n",
    "                      \"start\" : start,\n",
    "                    # for end, use 1st day of month following final month of data\n",
    "                      \"end\" : end\n",
    "                 }\n",
    "        \n",
    "        f_name = api + \"-\" + acs + \"-\" + start[0:-4] + \"-\" + end[0:-4] + \".json\"\n",
    "        json.dump(api_call(end_point, params), open(f_name,\"w\"))\n",
    "    \n",
    "    return\n",
    "\n",
    "# generate csv file from json data\n",
    "def csv_gen():\n",
    "    # retrieve data from json files\n",
    "    df_pagecount_desktop = pd.DataFrame(json.load(open('pagecounts-desktop-site-200801-201608.json', 'r'))['items'], columns=['access-site','count','timestamp']).rename(columns = {\"count\" : \"pagecount_desktop_views\", \"access-site\" : \"access\"})\n",
    "    df_pagecount_mobile = pd.DataFrame(json.load(open('pagecounts-mobile-site-200801-201608.json', 'r'))['items'], columns=['access-site','count','timestamp']).rename(columns = {\"count\" : \"pagecount_mobile_views\", \"access-site\" : \"access\"})\n",
    "    df_pageview_desktop = pd.DataFrame(json.load(open('pageviews-desktop-201507-201909.json', 'r'))['items'], columns=['access', 'timestamp','views']).rename(columns = {\"views\" : \"pageview_desktop_views\"})\n",
    "    df_pageview_mobile = pd.DataFrame(json.load(open('pageviews-mobile-web-201507-201909.json', 'r'))['items'], columns=['access', 'timestamp','views']).rename(columns = {\"views\" : \"pageview_mobile_views\"})\n",
    "    df_pageview_app = pd.DataFrame(json.load(open('pageviews-mobile-app-201507-201909.json', 'r'))['items'], columns=['access', 'timestamp','views']).rename(columns = {\"views\" : \"pageview_mobile_views\"})\n",
    "    # Combine page views for mobile-app and mobile-web\n",
    "    df_pageview_mobile['pageview_mobile_views'] += df_pageview_app['pageview_mobile_views']\n",
    "    \n",
    "    # add month and year columns\n",
    "    df_pagecount_desktop['year'] = df_pagecount_desktop['timestamp']\n",
    "    df_pagecount_desktop['month'] = df_pagecount_desktop['timestamp']\n",
    "    for i in range(0, len(df_pagecount_desktop)):\n",
    "        df_pagecount_desktop['year'][i] = df_pagecount_desktop['timestamp'][i][0:4]\n",
    "        df_pagecount_desktop['month'][i] = df_pagecount_desktop['timestamp'][i][4:6]\n",
    "\n",
    "    df_pagecount_mobile['year'] = df_pagecount_mobile['timestamp']\n",
    "    df_pagecount_mobile['month'] = df_pagecount_mobile['timestamp']\n",
    "    for i in range(0, len(df_pagecount_mobile)):\n",
    "        df_pagecount_mobile['year'][i] = df_pagecount_mobile['timestamp'][i][0:4]\n",
    "        df_pagecount_mobile['month'][i] = df_pagecount_mobile['timestamp'][i][4:6]\n",
    "\n",
    "    df_pageview_desktop['year'] = df_pageview_desktop['timestamp']\n",
    "    df_pageview_desktop['month'] = df_pageview_desktop['timestamp']\n",
    "    for i in range(0, len(df_pageview_desktop)):\n",
    "        df_pageview_desktop['year'][i] = df_pageview_desktop['timestamp'][i][0:4]\n",
    "        df_pageview_desktop['month'][i] = df_pageview_desktop['timestamp'][i][4:6]\n",
    "\n",
    "    df_pageview_mobile['year'] = df_pageview_mobile['timestamp']\n",
    "    df_pageview_mobile['month'] = df_pageview_mobile['timestamp']\n",
    "    for i in range(0, len(df_pageview_mobile)):\n",
    "        df_pageview_mobile['year'][i] = df_pageview_mobile['timestamp'][i][0:4]\n",
    "        df_pageview_mobile['month'][i] = df_pageview_mobile['timestamp'][i][4:6]\n",
    "    \n",
    "    # merge DataFrames\n",
    "    df_desktop = df_pagecount_desktop.merge(df_pageview_desktop, how='outer', on=['timestamp','year', 'month'])\n",
    "    df_mobile = df_pagecount_mobile.merge(df_pageview_mobile, how='outer', on=['timestamp','year', 'month'])\n",
    "    df_all_data = df_desktop.merge(df_mobile, how='outer', on=['timestamp','year', 'month']).fillna(0)\n",
    "    \n",
    "    # create wiki traffic DataFrame\n",
    "    cols = ['year', 'month', 'pagecount_all_views', 'pagecount_desktop_views', 'pagecount_mobile_views', \n",
    "        'pageview_all_views', 'pageview_desktop_views', 'pageview_mobile_views']\n",
    "    df_wiki_traffic = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    df_wiki_traffic['year'] = df_all_data['year']\n",
    "    df_wiki_traffic['month'] = df_all_data['month']\n",
    "    df_wiki_traffic['pagecount_all_views'] = df_all_data['pagecount_desktop_views'] + df_all_data['pagecount_mobile_views']\n",
    "    df_wiki_traffic['pagecount_desktop_views'] = df_all_data['pagecount_desktop_views']\n",
    "    df_wiki_traffic['pagecount_mobile_views'] = df_all_data['pagecount_mobile_views']\n",
    "    df_wiki_traffic['pageview_all_views'] = df_all_data['pageview_desktop_views'] + df_all_data['pageview_mobile_views']\n",
    "    df_wiki_traffic['pageview_desktop_views'] = df_all_data['pageview_desktop_views']\n",
    "    df_wiki_traffic['pageview_mobile_views'] = df_all_data['pageview_mobile_views']\n",
    "    \n",
    "    # Create csv file\n",
    "    df_wiki_traffic.to_csv('en-wikipedia_traffic_200712-201809.csv', index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing step. This will take some time.\n",
    "dump_pagecounts()\n",
    "dump_pageviews()\n",
    "csv_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('en-wikipedia_traffic_200712-201809.csv', sep=',')\n",
    "\n",
    "# Format dates for plotting\n",
    "dates = []\n",
    "for y,m in zip(df['year'], df['month']):\n",
    "    date = datetime.strptime(str(y)+str(m),\"%Y%m\")\n",
    "    dates.append(date)\n",
    "\n",
    "# Generate time series plot\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "main_legacy = df['pagecount_desktop_views'].replace(0,NaN)/1e6\n",
    "main_modern = df['pageview_desktop_views'].replace(0,NaN)/1e6\n",
    "ax.plot(dates, main_legacy,'g--', linewidth=2, label='main site')\n",
    "ax.plot(dates, main_modern,'g-', linewidth=2)\n",
    "\n",
    "mobile_legacy = df['pagecount_mobile_views'].replace(0,NaN)/1e6\n",
    "mobile_modern = df['pageview_mobile_views'].replace(0,NaN)/1e6\n",
    "ax.plot(dates, mobile_legacy,'b--', linewidth=2, label='mobile site')\n",
    "ax.plot(dates, mobile_modern,'b-', linewidth=2)\n",
    "\n",
    "total_legacy = df['pagecount_all_views'].replace(0,NaN)/1e6\n",
    "total_modern = df['pageview_all_views'].replace(0,NaN)/1e6\n",
    "ax.plot(dates, total_legacy,'k--', linewidth=2, label='total')\n",
    "ax.plot(dates, total_modern,'k-', linewidth=2)\n",
    "\n",
    "ax.set(ylabel=\"Page Views\", title=\"Page Views on English Wikipedia (x 1,000,000)\")\n",
    "ax.set_xlabel('May 2015: a new pageview definition took effect, which eliminated all crawler traffic. Solid lines mark new definition.',\n",
    "              fontsize='medium', fontweight='bold', c='r')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "date_form = DateFormatter(\"%Y\")\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the chart as a JPEG file\n",
    "fig.savefig('pageviews.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
